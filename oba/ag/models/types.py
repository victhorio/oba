import json
from typing import Generic, Literal, TypeVar

from attrs import define, field
from pydantic import BaseModel

Role = Literal["system", "user", "assistant"]
ModelID = Literal[
    "gpt-4.1",
    "gpt-5-nano",
    "gpt-5-mini",
    "gpt-5",
    "gpt-5.1",
]


@define(slots=True)
class Reasoning:
    # NOTE: We need to store reasoning blocks from OpenAI to maintain it in context,
    #       but they only accept returning encrypted reasoning contents.
    encrypted_content: str


@define(slots=True)
class Message:
    role: Role
    # TODO: support non text inputs as well
    content: str


@define(slots=True)
class ToolCall:
    call_id: str
    name: str
    args: str
    _parsed_args: dict[str, object] = field(init=False, factory=dict)

    @property
    def parsed_args(self) -> dict[str, object]:
        if self._parsed_args:
            return self._parsed_args

        self._parsed_args = json.loads(self.args)
        return self._parsed_args


@define(slots=True)
class ToolResult:
    call_id: str
    result: str


@define(slots=True)
class Usage:
    input_tokens: int
    output_tokens: int
    input_tokens_cached: int = 0
    output_tokens_reasoning: int = 0

    def total_cost(self, model: ModelID) -> float:
        assert model in _MODEL_COSTS, f"Unknown `model`: {model}"
        in_rate, cin_rate, out_rate = _MODEL_COSTS[model]
        in_cost = (self.input_tokens - self.input_tokens_cached) * in_rate
        cin_cost = self.input_tokens_cached * cin_rate
        out_cost = self.output_tokens * out_rate
        return (in_cost + cin_cost + out_cost) / 1e6


StructuredModelT = TypeVar("StructuredModelT", bound=BaseModel)


@define(slots=True)
class Response(Generic[StructuredModelT]):
    """
    A normalized response object.
    """

    model: ModelID
    """The model ID used when making the request."""
    model_api: str
    """The model ID returned by the API. Usually includes a date-based variant specifier."""
    usage: Usage
    """Object including token usage information."""
    content: str
    """Actual text content generated by the model. An empty string if the model did not generate any content."""
    tool_calls: list[ToolCall]
    """A list of the (potentially multiple) tool calls requested by the model. Empty if no tool calls were made."""
    structured_output: StructuredModelT | None
    """If this was a structured output request, this is the parsed PyDantic version of the content. Otherwise None."""
    reasoning: Reasoning | None
    """The reasoning from the model, if generated. Otherwise None."""

    @property
    def message(self) -> Message:
        """The message component from this response. Will have empty content if missing."""
        return Message(role="assistant", content=self.content)

    @property
    def total_cost(self) -> float:
        """The total dollar cost of this response."""
        return self.usage.total_cost(self.model)

    @property
    def messages(self) -> list["MessageTypes"]:
        """
        A list containing all available components from this response (reasoning, message, tool calls respectively).
        The message history can be extended with the list.
        """

        res: list["MessageTypes"] = list()
        if self.reasoning:
            res.append(self.reasoning)
        if self.content:
            res.append(self.message)
        if self.tool_calls:
            res.extend(self.tool_calls)
        return res


MessageTypes = Message | Reasoning | ToolCall | ToolResult
"""The different types that can make up a conversation history: messages, reasoning blocks, tool calls and tool results."""


# Model ID -> (Input cost, Cached input cost, Output cost) per 1M tokens
_MODEL_COSTS: dict[ModelID, tuple[float, float, float]] = {
    "gpt-4.1": (2.00, 0.50, 8.00),
    "gpt-5-nano": (0.05, 0.005, 0.40),
    "gpt-5-mini": (0.25, 0.025, 2.00),
    "gpt-5": (1.25, 0.125, 10.00),
    "gpt-5.1": (1.25, 0.125, 10.00),
}
